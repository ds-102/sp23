{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecb928",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab06.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd2334",
   "metadata": {},
   "source": [
    "# Lab 6: Nonparametric methods\n",
    "\n",
    "Welcome to the sixth DS102 lab! \n",
    "\n",
    "The goal of this lab is to explore and interpret several nonparametric methods for regression.\n",
    "\n",
    "The code you need to write is indicated with `...`. There is additional documentation for each part as you go along.\n",
    "\n",
    "In preparation for this lab we would recommend that you review the slides and demos from Lectures 13 and 14.\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "`<Collaborator Name> <Collaborator e-mail>`\n",
    "\n",
    "## Submission\n",
    "See the [Gradescope Submission Guidelines](https://edstem.org/us/courses/33922/discussion/2419862) for details on how to submit your lab.\n",
    "\n",
    "**For full credit, this assignment should be completed and submitted before Wednesday, March 15th, 2023 at 11:59 PM PDT.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee794ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import hashlib\n",
    "def get_hash(num, significance = 4):\n",
    "    num = round(num, significance)\n",
    "    \"\"\"Helper function for assessing correctness\"\"\"\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819f89b",
   "metadata": {},
   "source": [
    "# 1. Model comparison\n",
    "\n",
    "In this lab, we'll be working with the hybrid car dataset ([which you may remember from Data 8](https://inferentialthinking.com/chapters/15/1/Correlation.html)).\n",
    "\n",
    "It contains data on 153 different models of hybrid car from 1997 to 2013, with the price (`msrp`), gas mileage (`mpg`), type of car (`class`), and how fast the car accelerates in km/hour/second (`acceleration`).\n",
    "\n",
    "We're going to try to predict the price using other features of the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = pd.read_csv('hybrid.csv')\n",
    "\n",
    "X_cols = [\"year\", \"acceleration\", \"mpg\"] # Columns used for prediction\n",
    "y_col = \"msrp\" # The column we're trying to predict\n",
    "\n",
    "hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991766f2",
   "metadata": {},
   "source": [
    "This cell generates all pairs of scatterplots for numerical variables in the data. You should see the same trends discussed in the chapter of the Data 8 textbook linked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06cc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c044078",
   "metadata": {},
   "source": [
    "### 1(a) Splitting the data\n",
    "\n",
    "We'll start by splitting the data into training and test sets. Use the scikit-learn function `train_test_split` to make two dataframes called `train` and `test`. The test set should have $30\\%$ of the data (46 rows).\n",
    "\n",
    "The `train_test_split` function has an argument called `random_state` that lets you ensure that it uses the same random split every time: you should set that argument to `101` to pass the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b1fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "...\n",
    "train, test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7a668",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3624f36",
   "metadata": {},
   "source": [
    "### 1(b) Predicting the output\n",
    "\n",
    "#### 1.b.(i) Linear regression\n",
    "\n",
    "Use linear regression to predict the MSRP from year, acceleration, and MPG. Add a new column to the `train` and `test` dataframes called `linear_pred` with the predictions from linear regression.\n",
    "\n",
    "*Hint: throughout this lab, you should use the default values of all parameters for all models we're experimenting with.*\n",
    "\n",
    "*Hint: for this lab, you don't need to worry about pandas warnings about setting a value on a copy of a slice.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644754e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "...\n",
    "\n",
    "train[\"linear_pred\"] = ...\n",
    "test[\"linear_pred\"] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d762e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f56b1c",
   "metadata": {},
   "source": [
    "Run the following cell that computes the training set error and test set error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = np.mean((train[\"linear_pred\"] - train[\"msrp\"]) ** 2) ** 0.5\n",
    "test_rmse = np.mean((test[\"linear_pred\"] - test[\"msrp\"]) ** 2) ** 0.5\n",
    "\n",
    "print(\"Training set error for linear model:\", train_rmse)\n",
    "print(\"Test set error for linear model:    \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d6fe3",
   "metadata": {},
   "source": [
    "#### 1.b.(ii) Decision Trees\n",
    "\n",
    "Recall that a decision tree is a method for classification and regression that uses a tree-like structure to decide what value to predict for a point.\n",
    "\n",
    "\n",
    "In this question, we'll use a decision tree for regression instead of classification. When we built a decision tree for classification in lecture, we made decisions about splitting based on how homogeneous the $y$-values were. Now, we'll instead make splits based on the residuals for predicting at that node. \n",
    "\n",
    "Let's look at an example, assuming we're using mean squared error as our loss. For example, if we make our first split based on whether or not `mpg <= M`, we'll have some average MSRP for the low-MPG cars (below `M`), along with residuals if we used that average to predict the MSRP for all the low-MPG cars. Similarly, we have the same information for the high-MPG cars (above `M`). A good value of `M` will make the mean squared residuals for the two groups as small as possible. So, at each node, we choose a split that makes the mean squared error on each side as small as possible.\n",
    "\n",
    "Compute the prediction from a decision tree with the default parameters for scikit-learn's `DecisionTreeRegressor` (i.e., no limit on tree depth). Add a new column to the `train` and `test` dataframes called `tree_pred` with the predictions from the decision tree.\n",
    "\n",
    "*Hint: your code should look very similar to your answer from 1.b.(i).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e7863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "...\n",
    "\n",
    "train[\"tree_pred\"] = ...\n",
    "test[\"tree_pred\"] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13989ac9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b_ii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c2d49",
   "metadata": {},
   "source": [
    "Run the following cell that computes the training set error and test set error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ca782",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = np.mean((train[\"tree_pred\"] - train[\"msrp\"]) ** 2) ** 0.5\n",
    "test_rmse = np.mean((test[\"tree_pred\"] - test[\"msrp\"]) ** 2) ** 0.5\n",
    "\n",
    "print(\"Training set error for decision tree:\", train_rmse)\n",
    "print(\"Test set error for decision tree:    \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45763674",
   "metadata": {},
   "source": [
    "#### 1.b.(iii) Random Forest\n",
    "\n",
    "Recall that a random forest is the combination of a large number of decision trees.\n",
    "\n",
    "Compute the prediction from a decision tree using scikit-learn's `RandomForestRegressor`, with the following parameters:\n",
    "* 100 trees (default)\n",
    "* no limit on each tree's depth (default)\n",
    "* Use the `max_features` parameter to only use one feature for each tree. (*The recommended value for random forests is for each tree to only use 1/3 of the features, and in this case we have 3 features.*)\n",
    "\n",
    "Add a new column to the `train` and `test` dataframes called `forest_pred` with the predictions from the random forest.\n",
    "\n",
    "*Hint: your code should look very similar to your answers from 1.b.(i) and 1.b.(ii).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0263a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(max_features=1)\n",
    "\n",
    "...\n",
    "\n",
    "train[\"forest_pred\"] = ...\n",
    "test[\"forest_pred\"] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb8a2a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b_iii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb158b",
   "metadata": {},
   "source": [
    "Run the following cell that computes the training set error and test set error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = np.mean((train[\"forest_pred\"] - train[\"msrp\"]) ** 2) ** 0.5\n",
    "test_rmse = np.mean((test[\"forest_pred\"] - test[\"msrp\"]) ** 2) ** 0.5\n",
    "\n",
    "print(\"Training set error for random forest:\", train_rmse)\n",
    "print(\"Test set error for random forest:    \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d10e7f",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1(c) accuracy comparison\n",
    "\n",
    "Of the Decision Tree model and the Random Forest model, which one does best on the training set? Why? Which model does best on the test set? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0d9e1",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21bd0b",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 1.d Interpretability\n",
    "\n",
    "#### 1.d.i Linear Regression\n",
    "\n",
    "Let's look at the coefficients from the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can just run this cell to print out the coefficients for each feature:\n",
    "print(X_cols)\n",
    "linear_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3d629",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Using this result, fill in the blanks in the following two statements:\n",
    "\n",
    "\"Each year, linear regression predicts that the average price changes by $\\$ \\rule{1cm}{0.15mm}$ \". (Your answer should be a positive or negative number)\n",
    "\n",
    "\"Linear regression predicts that cars with better gas mileage are $\\rule{1cm}{0.15mm}$ expensive.\" (Your answer should be either 'more' or 'less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56597157",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786f0856",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### 1.d.ii Decision trees\n",
    "\n",
    "We'll use the `plot_tree` function to draw the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a18746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(16, 4))\n",
    "plot_tree(tree_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1842c",
   "metadata": {},
   "source": [
    "We can see that the tree is quite deep and complex. Let's take a closer look at the nodes at the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b95937",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree_model, max_depth=2, fontsize=14, feature_names=X_cols);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a7efd",
   "metadata": {},
   "source": [
    "There are a few things we can see right away:\n",
    "\n",
    "\n",
    "* The first line tells us which feature to split on: values below the threshold go to the left, and values above go to the right.\n",
    "* The third line tells us the number of training samples that made it that far into the tree.\n",
    "* The fourth line tells us the average $y$-value (in this case, MSRP) of all the training samples that made it that far into the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a24221",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Just by looking at the first few layers, we can already see that the decision tree has pulled out the most expensive cars into some of the branches, and the less expensive ones into other branches.\n",
    "\n",
    "Suppose we had stopped growing the tree at this point. That would have given us four leaf nodes, each with very different mean MSRP. Describe the node that contains the most expensive cars in plain English."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4878cf0",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fa9e0",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Random Forests\n",
    "\n",
    "Unfortunately, random forests are much harder to interpret than either of the other two methods that we've tried. In this case, with so few features, we might be able to look at the top of each tree and find similarities across most or all of the trees, but in high-dimensional problems, each tree should see a very different subset of features, and this becomes much harder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f49e9e",
   "metadata": {},
   "source": [
    "# 2. Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6da638",
   "metadata": {},
   "source": [
    "Many methods for explainable ML use the following setup to explain a specific prediction from a complex model:\n",
    "\n",
    "1. Construct a simpler, easier-to-explain model (e.g., linear regression, decision tree, etc.) that behaves similarly to the complex model for data points near the specific point we're trying to explain.\n",
    "2. Interpret the simpler model.\n",
    "\n",
    "In this question, we'll try to see if we can come up with an explanation for the worst predictions from each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18466d",
   "metadata": {},
   "source": [
    "### 2.a Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87fcb5a",
   "metadata": {},
   "source": [
    "#### 2.a.i Finding the worst predictions\n",
    "\n",
    "Find the two cars in the test set where linear regression does the worst (i.e., has the highest absolute error). Your answer should be a dataframe with two rows from `test`, one for the worst error followed by one for the second-worst error. While solving this problem, you can add extra columns to `test` if you wish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913dcac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hint: There are a couple of ways to do this. One suggestion is to first create new column with the \n",
    "# absolute linear error and then sort the dataframe based on this absolute linear error.\n",
    "\n",
    "...\n",
    "worst_linear_predicted_cars_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82fd2e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a_i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_linear_predicted_cars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb98957",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### 2.a.ii Explanation\n",
    "\n",
    "Using the coefficients of the linear model that we found earlier, explain why linear regression's predictions for these two cars were the way they were. Is the explanation from the linear model consistent with the trends you observed at the beginning in the visualizations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e772ff7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06791a4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 2.b: Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d9e56",
   "metadata": {},
   "source": [
    "#### 2.b.i Finding the worst predictions for the random forest\n",
    "\n",
    "Find the two cars in the test set where random forest does the worst (i.e., has the highest absolute error). Your answer should be a dataframe with two rows from `test`, one for each of the two cars. You can add extra columns to `test` if you wish.\n",
    "\n",
    "*Hint: your code should be very similar to your code for 2.a.i.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f54f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "worst_forest_predicted_cars_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56135e7a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b_i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105912e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_forest_predicted_cars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac745df",
   "metadata": {},
   "source": [
    "# 3 Feature Engineering and Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a818c585",
   "metadata": {},
   "source": [
    "In this question, we will be exploring the effect of feature engineering on the interpretability of a given model using a toy dataset. Let's start by loading the data, which has already been split for you into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41897622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same plotting function from lecture\n",
    "\n",
    "def draw_results(x1, x2, color, plot_title=''):\n",
    "    plt.figure()\n",
    "    plt.scatter(x1, x2, c=color, cmap='viridis', alpha=0.7);\n",
    "    plt.colorbar()\n",
    "    plt.title(plot_title)\n",
    "    plt.axis('equal')\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "ring_train = pd.read_csv('ring_train.csv')\n",
    "ring_test = pd.read_csv('ring_test.csv')\n",
    "draw_results(ring_train['x1'], ring_train['x2'], color=ring_train['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ef924",
   "metadata": {},
   "source": [
    "We know from lecture that without any additional features, logistic regression will use a line as a decision boundary. \n",
    "Where would you draw the best line to classify these points? (No need to answer, but please think about it.)\n",
    "\n",
    "We are now going to fit a simple logistic regression model on the data using the following lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to write any code here: just understand.\n",
    "X_train = ring_train[['x1', 'x2']].values\n",
    "y_train = ring_train['y'].values\n",
    "\n",
    "X_test = ring_test[['x1', 'x2']].values\n",
    "y_test = ring_test['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to write any code here: just understand.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = ring_train[['x1', 'x2']].values\n",
    "y_train = ring_train['y'].values\n",
    "\n",
    "X_test = ring_test[['x1', 'x2']].values\n",
    "y_test = ring_test['y'].values\n",
    "\n",
    "model_simple_features = LogisticRegression(\n",
    "    penalty='none', solver='lbfgs'\n",
    ")\n",
    "\n",
    "model_simple_features.fit(X_test, y_test)\n",
    "\n",
    "probs = model_simple_features.predict_proba(X_test)[:, 1]\n",
    "y_hat = (probs > 0.5).astype(np.int64)\n",
    "\n",
    "draw_results(\n",
    "    X_test[:, 0], X_test[:, 1], color=probs, \n",
    "    plot_title=\"Logistic regression predicted probs (no feature eng)\"\n",
    ")\n",
    "draw_results(\n",
    "    X_test[:, 0], X_test[:, 1], color=y_hat, \n",
    "    plot_title=\"Logistic regression prediction (no feature eng)\"\n",
    ")\n",
    "\n",
    "accuracy = np.mean(y_test == y_hat)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d37405",
   "metadata": {},
   "source": [
    "Comparing the labels classified by the model with the true labels, we notice that the simple logistic regression model is not ideal partly because the true decision boundary is nonlinear. In order to improve on the model, we will engineer new features. \n",
    "\n",
    "With the checkerboard dataset, we engineered a new feature, $x_1 \\times x_2$, which was just what we needed. For this dataset, the feature that we need is a little more complicated.\n",
    "\n",
    "Instead, we'll take inspiration from neural networks, and add many random features, where each is a random linear combination of the inputs, where the coefficients will be random numbers between -1 and 1.\n",
    "\n",
    "Don't forget that we also need to apply a nonlinearity, or else the linear combinations won't help us when applying logistic regression. In this example, we'll use the sigmoid function. For example, one feature might be $\\sigma(-0.37x_1 + 0.82x_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f2a70",
   "metadata": {},
   "source": [
    "### 3.a Add random features\n",
    "\n",
    "Complete the cell below to add random features to the dataset. As described above, we first generate a pair of coefficients $(c_1, c_2)$ uniformly random from $(-1, 1)$ and then for both the training set and the test set, add an additional column whose values are $\\sigma(c_1x_1 + c_2 x_2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e942a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def add_random_feature(train_data, test_data):\n",
    "    # Returns the modified train_data and test_data\n",
    "    coeffs = ...\n",
    "    # This code gives the feature a convenient name\n",
    "    feat_name = f\"Ïƒ({coeffs[0]:0.2f}x1 + {coeffs[1]:0.2f}x2)\"\n",
    "\n",
    "    for dataset in (train_data, test_data):\n",
    "        linear_combination = np.dot(dataset[['x1', 'x2']], coeffs)\n",
    "        feature = ...\n",
    "        dataset[feat_name] = feature\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e7831",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77dfdc",
   "metadata": {},
   "source": [
    "Using the code you completed in 3a, we can now add 10 random features to both the training set and the test set using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b665c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell uses the code you wrote to add 10 random features to the\n",
    "# train and test sets.\n",
    "\n",
    "ring_train_feats = ring_train.copy()\n",
    "ring_test_feats = ring_test.copy()\n",
    "for i in range(10):\n",
    "    ring_train_feats, ring_test_feats = (\n",
    "        add_random_feature(ring_train_feats, ring_test_feats)\n",
    "    )\n",
    "ring_train_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fc5b4",
   "metadata": {},
   "source": [
    "We can now train a new logistic regression model with these 10 additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca18c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to write any code here: just understand.\n",
    "X_train = ring_train_feats.iloc[:, 1:].values\n",
    "y_train = ring_train_feats['y'].values\n",
    "\n",
    "X_test = ring_test_feats.iloc[:, 1:].values\n",
    "y_test = ring_test_feats['y'].values\n",
    "\n",
    "model_features = LogisticRegression(\n",
    "    penalty='none', solver='lbfgs'\n",
    ")\n",
    "\n",
    "model_features.fit(X_train, y_train)\n",
    "\n",
    "probs = model_features.predict_proba(X_test)[:, 1]\n",
    "y_hat = (probs > 0.5).astype(np.int64)\n",
    "\n",
    "draw_results(\n",
    "    X_test[:, 0], X_test[:, 1], color=probs, \n",
    "    plot_title=\"Logistic regression predicted probs (random features)\"\n",
    ")\n",
    "\n",
    "draw_results(\n",
    "    X_test[:, 0], X_test[:, 1], color=y_hat, \n",
    "    plot_title=\"Logistic regression prediction (random features)\"\n",
    ")\n",
    "\n",
    "accuracy = np.mean(y_test == y_hat)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37d228",
   "metadata": {},
   "source": [
    "You should see that the accuracy is already better. Now that our model has improved, let's try to interpret it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96887c7b",
   "metadata": {},
   "source": [
    "### 3.b Coefficients\n",
    "\n",
    "Fill in the blanks in the following code that creates a dataframe with the coefficients from the logistic regression model.\n",
    "\n",
    "*Hint: you may find it helpful to refer to the demo from lecture.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e9d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = ring_train_feats.columns[1:]\n",
    "logistic_coeff_vals = ...\n",
    "len(logistic_coeff_vals)\n",
    "coefficient_df = pd.DataFrame(\n",
    "    {'feature': feature_names, 'coefficients': logistic_coeff_vals}\n",
    ")\n",
    "\n",
    "coefficient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a04a61",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d212c3",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3c Interpretibility\n",
    "\n",
    "This model has better performance on the data but at the same time, it loses some interpretability. Explain why this logistic regression model is harder to interpret than the simpler (and worse-performing) one from earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa5a3f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3616d10",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89039af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dcb4b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5ee9b",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> checks = [get_hash(train.iloc[:,:6]) == '93f897c99882bbc06bcd6faa779cc6d3',\n...           get_hash(test.iloc[:,:6]) == '7382e376c3ee239052f41ac438f1b00b']\n>>> assert np.all(checks)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b_i": {
     "name": "q1b_i",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(linear_model, LinearRegression)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> checks = [get_hash(train[\"linear_pred\"]) == 'f742b6eb4aac9114e81c605606a6f9c8',\n...           get_hash(test[\"linear_pred\"]) == '52001a2c72bc56175a048e7058ec085f']\n>>> assert np.all(checks)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b_ii": {
     "name": "q1b_ii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(tree_model, DecisionTreeRegressor)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_hash(train['tree_pred']) == '46870ecc44b66f5acaafaa5af460ae79'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b_iii": {
     "name": "q1b_iii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(forest_model, RandomForestRegressor)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert forest_model.max_features != 'auto'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> checks = [((train[\"forest_pred\"] - train[\"msrp\"])**2).mean() < 30000000.0,\n...           ((test[\"forest_pred\"] - test[\"msrp\"]) **2).mean() < 210000000.0]\n>>> assert np.all(checks)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a_i": {
     "name": "q2a_i",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> answers = ['Lexus LS600h/hL', 'S400 Long']\n>>> assert np.all(worst_linear_predicted_cars_df['vehicle'].isin(answers))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b_i": {
     "name": "q2b_i",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> answers = ['Lexus LS600h/hL', 'S400 Long']\n>>> assert np.all(worst_forest_predicted_cars_df['vehicle'].isin(answers))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ring_train_copy3a, ring_test_copy3a = ring_train.copy(), ring_test.copy()\n>>> np.random.seed(42)\n>>> _,_ = add_random_feature(ring_train_copy3a, ring_test_copy3a)\n>>> _,_ = add_random_feature(ring_train_copy3a, ring_test_copy3a)\n>>> checks = [get_hash(ring_train_copy3a.iloc[:,-2]) == '14ef2ae3a9fb084922404362bb715541',\n...           get_hash(ring_train_copy3a.iloc[:,-1]) == 'ecb3610db652a969fb1bd630e818c965']\n>>> assert np.all(checks)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> checks = [coefficient_df.shape == (12, 2),\n...           coefficient_df['feature'][0] == 'x1',\n...           coefficient_df['feature'][1] == 'x2']\n>>> assert np.all(checks)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
